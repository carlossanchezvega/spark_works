{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARLOS S√ÅNCHEZ VEGA\n",
    "\n",
    "# RDD EXERCISES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the spark configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"RDDsExercises\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"u.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\t242\t3\t881250949\n",
      "186\t302\t3\t891717742\n",
      "22\t377\t1\t878887116\n",
      "244\t51\t2\t880606923\n",
      "166\t346\t1\t886397596\n",
      "298\t474\t4\t884182806\n",
      "115\t265\t2\t881171488\n",
      "253\t465\t5\t891628467\n",
      "305\t451\t3\t886324817\n",
      "6\t86\t3\t883603013\n"
     ]
    }
   ],
   "source": [
    "for i in lines.take(10):print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <strong>Question: taking into account the previous RDD, get the number of times a mark (3 column) is given</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = lines.map(lambda l: int(l.split()[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The are asking us to get the number of occurrences of a mark in the RDD, so we could use, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ratings.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([27145, 6110, 11370, 34174, 21201])\n"
     ]
    }
   ],
   "source": [
    "print(results.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result is provided as a dict. We format the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6110\n",
      "2 11370\n",
      "3 27145\n",
      "4 34174\n",
      "5 21201\n"
     ]
    }
   ],
   "source": [
    "for key, value in sortedResults.items():\n",
    "    print(\"%s %i\" % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. <strong>Get the average number of friends broken down by age</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"RDD2\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we load data into an RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"fakefriends.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,Will,33,385\n",
      "1,Jean-Luc,26,2\n",
      "2,Hugh,55,221\n",
      "3,Deanna,40,465\n",
      "4,Quark,68,21\n",
      "5,Weyoun,59,318\n",
      "6,Gowron,37,220\n",
      "7,Will,54,307\n",
      "8,Jadzia,38,380\n",
      "9,Hugh,27,181\n"
     ]
    }
   ],
   "source": [
    "for i in lines.take(10):print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>First column: identifier</li>\n",
    "<li>Second column: name</li>\n",
    "<li>Third column: age</li>\n",
    "<li>Fourth column: number of friends</li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to parse data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseLine(line):\n",
    "    fields = line.split(',')\n",
    "    age = int(fields[2])\n",
    "    numFriends = int(fields[3])\n",
    "    return (age, numFriends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = lines.map(parseLine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list of (age#friends) in our rdd to solve the problem:\n",
    "We are going to split up the solution in two parts:\n",
    "1) for every value, we will create a counter:\n",
    "Say we have (33, 385) =>  For each pair, we will take (numberOfFriends, 1) being \"1\" somehow a counter . So, we will create the next structure:\n",
    "(33, 385) =>  (33, (385,1))\n",
    "So, the first part is:\n",
    "rdd.mapValues(lambda x(x,1)\n",
    "\n",
    "2) For the rdd, we will create a data structure (totalFriendsForThatAge, numberOfPeopleOfThatAge). Example:\n",
    "(33,385) => (33, (385,1))\n",
    "\n",
    "For every tuple:\n",
    "(33,385) => (33, (385,1))\n",
    "(33, (385,1)) + (33,2) => (385 +2, 1+1)   => (33, (387,2))\n",
    "so we have to do (x[0] + y[0], x[1]+y[1]))\n",
    "\n",
    "As we are grouping by this defined function, we must use the reduceByKey function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalsByAge = rdd.mapValues(lambda x: (x,1)).reduceByKey(lambda x,y: (x[0] + y[0], x[1] + x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, (3904, 2048))\n",
      "(26, (4115, 65536))\n",
      "(55, (3842, 4096))\n",
      "(40, (4264, 65536))\n",
      "(68, (2696, 512))\n",
      "(59, (1980, 256))\n",
      "(37, (2244, 256))\n",
      "(54, (3615, 4096))\n",
      "(38, (2903, 16384))\n",
      "(27, (1825, 128))\n"
     ]
    }
   ],
   "source": [
    "for i in totalsByAge.take(10):print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having this tuple:\n",
    "    (33, (3904, 2048))\n",
    "to calculate the average we must divide the number of total friends (3904) / total number of persons of that age (2048)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 1.90625)\n",
      "(26, 0.0627899169921875)\n",
      "(55, 0.93798828125)\n",
      "(40, 0.0650634765625)\n",
      "(68, 5.265625)\n",
      "(59, 7.734375)\n",
      "(37, 8.765625)\n",
      "(54, 0.882568359375)\n",
      "(38, 0.17718505859375)\n",
      "(27, 14.2578125)\n",
      "(53, 24.375)\n",
      "(57, 1.5166015625)\n",
      "(56, 57.5)\n",
      "(43, 25.21875)\n",
      "(36, 4.81640625)\n",
      "(22, 22.578125)\n",
      "(35, 13.2265625)\n",
      "(45, 0.982421875)\n",
      "(60, 22.171875)\n",
      "(67, 0.10479736328125)\n",
      "(19, 2.291015625)\n",
      "(30, 2.533203125)\n",
      "(51, 33.046875)\n",
      "(25, 2.12109375)\n",
      "(21, 21.9296875)\n",
      "(42, 56.90625)\n",
      "(49, 34.625)\n",
      "(48, 5.49609375)\n",
      "(50, 79.5625)\n",
      "(39, 18.515625)\n",
      "(32, 2.2333984375)\n",
      "(58, 1.251953125)\n",
      "(64, 1.6484375)\n",
      "(31, 16.703125)\n",
      "(52, 3.6591796875)\n",
      "(24, 73.0625)\n",
      "(20, 51.5625)\n",
      "(62, 0.70068359375)\n",
      "(41, 9.44140625)\n",
      "(44, 1.6533203125)\n",
      "(69, 4.59375)\n",
      "(65, 93.1875)\n",
      "(61, 9.0078125)\n",
      "(28, 4.083984375)\n",
      "(66, 9.71875)\n",
      "(46, 0.7099609375)\n",
      "(29, 1.26513671875)\n",
      "(18, 21.4609375)\n",
      "(47, 8.19921875)\n",
      "(34, 46.03125)\n",
      "(63, 192.0)\n",
      "(23, 4.810546875)\n"
     ]
    }
   ],
   "source": [
    "averagesByAge = totalsByAge.mapValues(lambda x: x[0] / x[1])\n",
    "results = averagesByAge.collect()\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning that:\n",
    "    (33, 1.90625)\n",
    "For the age of 33, the average number of friends is 1.90625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. <strong>Get the min temperature for each station</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"MinTemperatures\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"1800.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITE00100554,18000101,TMAX,-75,,,E,\n",
      "ITE00100554,18000101,TMIN,-148,,,E,\n",
      "GM000010962,18000101,PRCP,0,,,E,\n",
      "EZE00100082,18000101,TMAX,-86,,,E,\n",
      "EZE00100082,18000101,TMIN,-135,,,E,\n",
      "ITE00100554,18000102,TMAX,-60,,I,E,\n",
      "ITE00100554,18000102,TMIN,-125,,,E,\n",
      "GM000010962,18000102,PRCP,0,,,E,\n",
      "EZE00100082,18000102,TMAX,-44,,,E,\n",
      "EZE00100082,18000102,TMIN,-130,,,E,\n"
     ]
    }
   ],
   "source": [
    "for i in lines.take(10):print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>First column: station</li>\n",
    "<li>Second column: code of the station</li>\n",
    "<li>Third column: entry type (TMIN, TMAX...)</li>\n",
    "<li>Fourth column: temperature</li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the purpose of formatting the data entry, we create the next function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseLine(line):\n",
    "    fields = line.split(',')\n",
    "    stationID = fields[0]\n",
    "    entryType = fields[2]\n",
    "    temperature = float(fields[3]) * 0.1 * (9.0 / 5.0) + 32.0\n",
    "    return (stationID, entryType, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedLines = lines.map(parseLine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have to get the min temperature, we filter entry type as \"TMIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "minTemps = parsedLines.filter(lambda x: \"TMIN\" in x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use the reduceByKey as the aggregate function to calculate the min:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationTemps = minTemps.map(lambda x: (x[0], x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITE00100554\t90.14F\n",
      "EZE00100082\t90.14F\n"
     ]
    }
   ],
   "source": [
    "minTemps = stationTemps.reduceByKey(lambda x, y: max(x,y))\n",
    "results = minTemps.collect()\n",
    "\n",
    "for result in results:\n",
    "    print(result[0] + \"\\t{:.2f}F\".format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <strong>Get the max temperature for each station</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"MaxTemperatures\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTemps = parsedLines.filter(lambda x: \"TMAX\" in x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationMaxTemps = maxTemps.map(lambda m: (m[0],m[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTemps = stationMaxTemps.reduceByKey(lambda x,y: max(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ITE00100554', 90.14000000000001)\n",
      "('EZE00100082', 90.14000000000001)\n"
     ]
    }
   ],
   "source": [
    "for i in maxTemps.take(10):print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We format the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITE00100554\t90.14F\n",
      "EZE00100082\t90.14F\n"
     ]
    }
   ],
   "source": [
    "results = maxTemps.collect()\n",
    "for temp in results:\n",
    "    print(temp[0] + \"\\t{:.2f}F\".format(temp[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. <strong>Get the word count in a book</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"wordCount\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"Book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = lines.flatMap(lambda w: w.split()).map(lambda w: (w,1)).reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Self-Employment:', 1)\n",
      "('Building', 5)\n",
      "('an', 172)\n",
      "('Internet', 13)\n",
      "('Business', 19)\n",
      "('of', 941)\n",
      "('One', 12)\n",
      "('Achieving', 1)\n",
      "('Financial', 3)\n",
      "('and', 901)\n"
     ]
    }
   ],
   "source": [
    "for i in wordCount.take(10):print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Employment: 1\n",
      "Building 5\n",
      "an 172\n",
      "Internet 13\n",
      "Business 19\n",
      "of 941\n",
      "One 12\n",
      "Achieving 1\n",
      "Financial 3\n",
      "and 901\n",
      "Personal 3\n",
      "Freedom 7\n",
      "through 55\n",
      "a 1148\n",
      "Lifestyle 5\n",
      "Technology 2\n",
      "By 9\n",
      "Frank 10\n",
      "Kane 7\n",
      "Copyright 1\n",
      "2015 3\n",
      "Kane. 1\n",
      "All 13\n",
      "rights 3\n",
      "reserved 2\n",
      "worldwide. 2\n",
      "CONTENTS 1\n",
      "Disclaimer 1\n",
      "Preface 1\n"
     ]
    }
   ],
   "source": [
    "for word, count in wordCount.collect()[:30]:\n",
    "    cleanWord = word.encode('ascii', 'ignore')\n",
    "    if (cleanWord):\n",
    "        print(cleanWord.decode() + \" \" + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We format the putput:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also choose the next option to solve the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = lines.flatMap(lambda w: w.split()).countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Employment: 1\n",
      "Building 5\n",
      "an 172\n",
      "Internet 13\n",
      "Business 19\n",
      "of 941\n",
      "One 12\n",
      "Achieving 1\n",
      "Financial 3\n",
      "and 901\n",
      "Personal 3\n",
      "Freedom 7\n",
      "through 55\n",
      "a 1148\n",
      "Lifestyle 5\n",
      "Technology 2\n",
      "By 9\n",
      "Frank 10\n",
      "Kane 7\n",
      "Copyright 1\n",
      "2015 3\n",
      "Kane. 1\n",
      "All 13\n",
      "rights 3\n",
      "reserved 2\n",
      "worldwide. 2\n",
      "CONTENTS 1\n",
      "Disclaimer 1\n",
      "Preface 1\n"
     ]
    }
   ],
   "source": [
    "for word, count in list(words.items())[0:30]:\n",
    "    cleanWord = word.encode('ascii', 'ignore')\n",
    "    if (cleanWord):\n",
    "        print(cleanWord.decode() + \" \" + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we showed in the output above, the result show was not totally correct aswords in capital letters are considered different from those in lower case letter. We could improve the result by creating a regular expression filtering the result we don't want to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeWords(text):\n",
    "    return re.compile(r'\\W+', re.UNICODE).split(text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we pass the previous function to the flatMap function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "words = lines.flatMap(normalizeWords)\n",
    "wordCounts = words.countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. <strong>Sort the result shown from the word count above</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = words.map(lambda w: (w,1)).reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('self', 111)\n",
      "('employment', 75)\n",
      "('building', 33)\n",
      "('an', 178)\n",
      "('internet', 26)\n",
      "('business', 383)\n",
      "('of', 970)\n",
      "('one', 100)\n",
      "('achieving', 1)\n",
      "('financial', 17)\n"
     ]
    }
   ],
   "source": [
    "for i in results.take(10):print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = words.map(lambda w: (w,1)).reduceByKey(lambda x,y:x+y).map(lambda w: (w[1],w[0])).sortByKey(False).map(lambda w: (w[1],w[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we create a map function so as to count the number of elements (reduceByKey). Then, we change the order of the elements in the tuple to use the \"sortByKey\" function. Finally, we re-order the elements (word, numberOccurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('you', 1878)\n",
      "('to', 1828)\n",
      "('your', 1420)\n",
      "('the', 1292)\n",
      "('a', 1191)\n",
      "('of', 970)\n",
      "('and', 934)\n",
      "('', 772)\n",
      "('that', 747)\n",
      "('it', 649)\n"
     ]
    }
   ],
   "source": [
    "for i in results.take(10):print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We format the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you 1878\n",
      "to 1828\n",
      "your 1420\n",
      "the 1292\n",
      "a 1191\n",
      "of 970\n",
      "and 934\n",
      "that 747\n",
      "it 649\n",
      "in 616\n",
      "is 560\n",
      "for 537\n",
      "on 428\n",
      "are 424\n",
      "if 411\n",
      "s 391\n",
      "i 387\n",
      "business 383\n",
      "can 376\n",
      "be 369\n",
      "as 343\n",
      "have 321\n",
      "with 315\n",
      "t 301\n",
      "this 280\n",
      "or 278\n",
      "time 255\n",
      "but 242\n",
      "they 234\n"
     ]
    }
   ],
   "source": [
    "for word, count in results.collect()[:30]:\n",
    "    cleanWord = word.encode('ascii', 'ignore')\n",
    "    if (cleanWord):\n",
    "        print(cleanWord.decode() + \" \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. <strong>Get the total amount per customer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"AmountPerCustomer\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account the next data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = sc.textFile(\"customer-orders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44,8602,37.19\n",
      "35,5368,65.89\n",
      "2,3391,40.64\n",
      "47,6694,14.98\n",
      "29,680,13.08\n",
      "91,8900,24.59\n",
      "70,3959,68.68\n",
      "85,1733,28.53\n",
      "53,9900,83.55\n",
      "14,1505,4.32\n"
     ]
    }
   ],
   "source": [
    "for i in input.take(10):print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>First column: customerId</li>\n",
    "<li>Second column: orderId</li>\n",
    "<li>Third column: price</li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to parse input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractCustomerPricePairs(line):\n",
    "    fields = line.split(',')\n",
    "    return (int(fields[0]), float(fields[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedInput = input.map(extractCustomerPricePairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalByCustomer = mappedInput.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = totalByCustomer.map(lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalByCustomerSorted = flipped.sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\t3309.38\n",
      "79\t3790.57\n",
      "96\t3924.23\n",
      "23\t4042.65\n",
      "99\t4172.29\n",
      "75\t4178.50\n",
      "36\t4278.05\n",
      "98\t4297.26\n",
      "47\t4316.30\n",
      "77\t4327.73\n",
      "13\t4367.62\n",
      "48\t4384.33\n",
      "49\t4394.60\n",
      "94\t4475.57\n",
      "67\t4505.79\n",
      "50\t4517.27\n",
      "78\t4524.51\n",
      "5\t4561.07\n",
      "57\t4628.40\n",
      "83\t4635.80\n",
      "91\t4642.26\n",
      "74\t4647.13\n",
      "84\t4652.94\n",
      "3\t4659.63\n",
      "12\t4664.59\n",
      "66\t4681.92\n",
      "56\t4701.02\n",
      "21\t4707.41\n",
      "80\t4727.86\n",
      "14\t4735.03\n"
     ]
    }
   ],
   "source": [
    "results = totalByCustomerSorted.collect()[:30];\n",
    "for result in results:\n",
    "    print(str(result[1]) + \"\\t{:.2f}\".format(result[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
